{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled31.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOu6JDOR9G7uYsPXmRTsecL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skarot/MlOps_AWS/blob/main/RegisterAndVizualizeWithSagemaker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AWS SageMaker - MLOPS\n"
      ],
      "metadata": {
        "id": "lE5CT5mKe96i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "We will ingest and transform the customer product reviews dataset. Then we will use AWS data stack services such as AWS Glue and Amazon Athena for ingesting and querying the dataset. Finally we will use AWS Data Wrangler to analyze the dataset and plot some visuals extracting insights."
      ],
      "metadata": {
        "id": "8SkircQlfIZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Preprocess data"
      ],
      "metadata": {
        "id": "3oF7YrOCfAHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install awscli --force-reinstall --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O0jQ_Qw7gYYw",
        "outputId": "909a82fa-24b4-454a-b9bd-ee8337efd613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting awscli\n",
            "  Using cached awscli-1.25.46-py3-none-any.whl (3.9 MB)\n",
            "Collecting botocore==1.27.46\n",
            "  Using cached botocore-1.27.46-py3-none-any.whl (9.0 MB)\n",
            "Collecting docutils<0.17,>=0.10\n",
            "  Using cached docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "Collecting PyYAML<5.5,>=3.10\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting colorama<0.4.5,>=0.2.5\n",
            "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting rsa<4.8,>=3.1.2\n",
            "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Using cached s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "Collecting python-dateutil<3.0.0,>=2.1\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 56.4 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Using cached urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
            "Collecting six>=1.5\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pyasn1>=0.1.3\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: six, urllib3, python-dateutil, jmespath, pyasn1, botocore, s3transfer, rsa, PyYAML, docutils, colorama, awscli\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.11\n",
            "    Uninstalling urllib3-1.26.11:\n",
            "      Successfully uninstalled urllib3-1.26.11\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: jmespath\n",
            "    Found existing installation: jmespath 1.0.1\n",
            "    Uninstalling jmespath-1.0.1:\n",
            "      Successfully uninstalled jmespath-1.0.1\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.4.8\n",
            "    Uninstalling pyasn1-0.4.8:\n",
            "      Successfully uninstalled pyasn1-0.4.8\n",
            "  Attempting uninstall: botocore\n",
            "    Found existing installation: botocore 1.27.46\n",
            "    Uninstalling botocore-1.27.46:\n",
            "      Successfully uninstalled botocore-1.27.46\n",
            "  Attempting uninstall: s3transfer\n",
            "    Found existing installation: s3transfer 0.6.0\n",
            "    Uninstalling s3transfer-0.6.0:\n",
            "      Successfully uninstalled s3transfer-0.6.0\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.7.2\n",
            "    Uninstalling rsa-4.7.2:\n",
            "      Successfully uninstalled rsa-4.7.2\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "  Attempting uninstall: colorama\n",
            "    Found existing installation: colorama 0.4.4\n",
            "    Uninstalling colorama-0.4.4:\n",
            "      Successfully uninstalled colorama-0.4.4\n",
            "  Attempting uninstall: awscli\n",
            "    Found existing installation: awscli 1.25.46\n",
            "    Uninstalling awscli-1.25.46:\n",
            "      Successfully uninstalled awscli-1.25.46\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.11 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-5.4.1 awscli-1.25.46 botocore-1.27.46 colorama-0.4.4 docutils-0.17.1 jmespath-1.0.1 pyasn1-0.4.8 python-dateutil-2.8.2 rsa-4.9 s3transfer-0.6.0 six-1.16.0 urllib3-1.26.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "pyasn1",
                  "six",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KisisY03e4XN",
        "outputId": "ca86df72-e8be-4225-c5dc-c7b73fcb83f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unable to locate credentials. You can configure credentials by running \"aws configure\".\n"
          ]
        }
      ],
      "source": [
        "!aws s3 ls s3://dlai-practical-data-science/data/raw/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "!aws configure\n",
        "'AWS Access Key ID [None]': 'AKIAIOSFODNN7EXAMPLE'\n",
        "'AWS Secret Access Key [None]': 'wJalrXUtnFEMI/K7MD ENG/bPxRfiCYEXAMPLEKEY',\n",
        "'Default region name [None]': 'us-west-2',\n",
        "'Default output format [None]': 'json'\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "75ueURYhi6ul",
        "outputId": "71c5cfa1-2eba-4aff-b6bd-fe2d1d2e46fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n!aws configure\\n'AWS Access Key ID [None]': 'AKIAIOSFODNN7EXAMPLE'\\n'AWS Secret Access Key [None]': 'wJalrXUtnFEMI/K7MD ENG/bPxRfiCYEXAMPLEKEY',\\n'Default region name [None]': 'us-west-2',\\n'Default output format [None]': 'json'\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!aws s3 cp s3://dlai-practical-data-science/data/raw/ ./womens_clothing_ecommerce_reviews.csv"
      ],
      "metadata": {
        "id": "m0vgQTfdzP2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to preprocess and trasform data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "oInS42ggi93r",
        "outputId": "f8bb80d6-1ffd-4dae-eccc-2f2737dfb0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-63d4b8c1ccbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAKIAIOSFODNN7EXAMPLE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'AKIAIOSFODNN7EXAMPLE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_transformed.to_csv('./womens_clothing_ecommerce_reviews_transformed.csv', index=False)"
      ],
      "metadata": {
        "id": "uwFHdzDpzjfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register the dataset for querying and visualizing"
      ],
      "metadata": {
        "id": "ycFl3vOWzHhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will register the public dataset into an S3-backed database table so you can query and visualize our dataset at scale."
      ],
      "metadata": {
        "id": "UIASz3CVz6yQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register S3 dataset files as a table for querying\n",
        "boto3 is the AWS SDK for Python to create, configure, and manage AWS services, such as Amazon Elastic Compute Cloud (Amazon EC2) and Amazon Simple Storage Service (Amazon S3). The SDK provides an object-oriented API as well as low-level access to AWS services.\n",
        "\n",
        "sagemaker is the SageMaker Python SDK which provides several high-level abstractions for working with the Amazon SageMaker."
      ],
      "metadata": {
        "id": "gfxp9-zu0RSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import sagemaker\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import botocore\n",
        "\n",
        "config = botocore.config.Config(user_agent_extra='dlai-pds/c1/w1')\n",
        "\n",
        "# low-level service client of the boto3 session\n",
        "sm = boto3.client(service_name='sagemaker', \n",
        "                  config=config)\n",
        "\n",
        "sess = sagemaker.Session(sagemaker_client=sm)                         \n",
        "\n",
        "bucket = sess.default_bucket()\n",
        "role = sagemaker.get_execution_role()\n",
        "region = sess.boto_region_name\n",
        "account_id = sess.account_id\n",
        "\n",
        "print('S3 Bucket: {}'.format(bucket))\n",
        "print('Region: {}'.format(region))\n",
        "print('Account ID: {}'.format(account_id))\n",
        "\n",
        "# The low level client SDK  boto3 that manages AWS services like AEC2 and S3, is passed as sagemaker client to the sagemaker session."
      ],
      "metadata": {
        "id": "ydwl_f9MzILB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An empty bucket should be created automatically for this account.\n",
        "Now we copy the transformed csv file to the newly created s3 bucket."
      ],
      "metadata": {
        "id": "qX0FMsLB1_wW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!aws s3 cp ./womens_clothing_ecommerce_reviews_transformed.csv s3://$bucket/data/transformed/womens_clothing_ecommerce_reviews_transformed.csv"
      ],
      "metadata": {
        "id": "pMg0qVEY164j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import AWS Data Wrangler"
      ],
      "metadata": {
        "id": "q9tpTOr-3PGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import AWS Data Wrangler\n",
        "\n",
        "AWS Data Wrangler is an AWS Professional Service open source python initiative that extends the power of Pandas library to AWS connecting dataframes and AWS data related services (Amazon Redshift, AWS Glue, Amazon Athena, Amazon EMR, Amazon QuickSight, etc).\n",
        "\n",
        "Built on top of other open-source projects like Pandas, Apache Arrow, Boto3, SQLAlchemy, Psycopg2 and PyMySQL, it offers abstracted functions to execute usual ETL tasks like load/unload data from data lakes, data warehouses and databases."
      ],
      "metadata": {
        "id": "Udl0JSml3Rpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import awswrangler as wr"
      ],
      "metadata": {
        "id": "gz44M49X3buZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create AWS Glue Catalog database"
      ],
      "metadata": {
        "id": "SZ5dKrN53oQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The data catalog features of AWS Glue and the inbuilt integration to Amazon S3 simplify the process of identifying data and deriving the schema definition out of the discovered data. Using AWS Glue crawlers within our data catalog, we can traverse our data stored in Amazon S3 and build out the metadata tables that are defined in our data catalog."
      ],
      "metadata": {
        "id": "pL_3SA8-3fo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wr.catalog.create_database(\n",
        "    name='dsoaws_deep_learning',\n",
        "    exist_ok=True\n",
        ")"
      ],
      "metadata": {
        "id": "N4MZkg7o2k4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "View the created database"
      ],
      "metadata": {
        "id": "nmTQZpcs71S4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbs = wr.catalog.get_databases()\n",
        "\n",
        "for db in dbs:\n",
        "    print(\"Database name: \" + db['Name'])"
      ],
      "metadata": {
        "id": "FwXzQoHU70Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register CSV data with AWS Glue Catalog"
      ],
      "metadata": {
        "id": "HdqtTGEy8J_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wr.catalog.create_csv_table(\n",
        "    database='dsoaws_deep_learning', # Replace None\n",
        "    path='s3://{}/data/transformed/'.format(bucket), \n",
        "    table=\"reviews\",    \n",
        "    columns_types={\n",
        "        'sentiment': 'int',        \n",
        "        'review_body': 'string',\n",
        "        'product_category': 'string'      \n",
        "    },\n",
        "    mode='overwrite',\n",
        "    skip_header_line_count=1,\n",
        "    sep=','\n",
        ")"
      ],
      "metadata": {
        "id": "OoIBYVoD8Kv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Review the registered table in the AWS Glue Catalog."
      ],
      "metadata": {
        "id": "t08JwtdQ8zbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table = wr.catalog.table(database='dsoaws_deep_learning',\n",
        "                         table='reviews')\n",
        "table"
      ],
      "metadata": {
        "id": "q9VT1zpJ80F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create s3 bucket to stores query results from AWS Athena"
      ],
      "metadata": {
        "id": "_dY6pFMZ9N9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# S3 bucket name\n",
        "wr.athena.create_athena_bucket()\n",
        "\n",
        "# EXPECTED OUTPUT\n",
        "# 's3://aws-athena-query-results-ACCOUNT-REGION/'"
      ],
      "metadata": {
        "id": "2c6n53sH9Ojz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize data"
      ],
      "metadata": {
        "id": "jTv5bP5U9sPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reviews dataset - column descriptions\n",
        "\n",
        "sentiment: The review's sentiment (-1, 0, 1).\n",
        "product_category: Broad product category that can be used to group reviews (in this case digital videos).\n",
        "review_body: The text of the review."
      ],
      "metadata": {
        "id": "OXSRfILN9vmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation for data visualization\n"
      ],
      "metadata": {
        "id": "ReGvhC279y0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'"
      ],
      "metadata": {
        "id": "8qqpSrCq9s0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "database_name = 'dsoaws_deep_learning'\n",
        "table_name = 'reviews'"
      ],
      "metadata": {
        "id": "ukBkSvfd-BRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#settings for visualization\n",
        "sns.set_style = 'seaborn-whitegrid'\n",
        "\n",
        "sns.set(rc={\"font.style\":\"normal\",\n",
        "            \"axes.facecolor\":\"white\",\n",
        "            'grid.color': '.8',\n",
        "            'grid.linestyle': '-',\n",
        "            \"figure.facecolor\":\"white\",\n",
        "            \"figure.titlesize\":20,\n",
        "            \"text.color\":\"black\",\n",
        "            \"xtick.color\":\"black\",\n",
        "            \"ytick.color\":\"black\",\n",
        "            \"axes.labelcolor\":\"black\",\n",
        "            \"axes.grid\":True,\n",
        "            'axes.labelsize':10,\n",
        "            'xtick.labelsize':10,\n",
        "            'font.size':10,\n",
        "            'ytick.labelsize':10})"
      ],
      "metadata": {
        "id": "RAJ5750m-D_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run SQL queries using Amazon Athena"
      ],
      "metadata": {
        "id": "0Ye4UkSx-JTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amazon Athena lets you query data in Amazon S3 using a standard SQL interface. It reflects the databases and tables in the AWS Glue Catalog. You can create interactive queries and perform any data manipulations required for further downstream processing.\n",
        "\n",
        "Standard SQL query can be saved as a string and then passed as a parameter into the Athena query. Run the following cells as an example to count the total number of reviews by sentiment. The SQL query here will take the following form:"
      ],
      "metadata": {
        "id": "7AJCyV_E-iba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the SQL statement to find the count of sentiments:\n",
        "statement_count_by_sentiment = \"\"\"\n",
        "SELECT sentiment, COUNT(sentiment) AS count_sentiment\n",
        "FROM reviews\n",
        "GROUP BY sentiment\n",
        "ORDER BY sentiment\n",
        "\"\"\"\n",
        "\n",
        "print(statement_count_by_sentiment)"
      ],
      "metadata": {
        "id": "O05j3asQ-F8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_count_by_sentiment = wr.athena.read_sql_query(\n",
        "    sql=statement_count_by_sentiment,\n",
        "    database=database_name\n",
        ")\n",
        "\n",
        "print(df_count_by_sentiment)"
      ],
      "metadata": {
        "id": "BNgPLmNs-1UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_count_by_sentiment.plot(kind='bar', x='sentiment', y='count_sentiment', rot=0)"
      ],
      "metadata": {
        "id": "YhF4o_Ss-5Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload image to S3 bucket\n",
        "sess.upload_data(path='avg_sentiment_per_category.png', bucket=bucket, key_prefix=\"images\")"
      ],
      "metadata": {
        "id": "KNlxeCZP_TC0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}